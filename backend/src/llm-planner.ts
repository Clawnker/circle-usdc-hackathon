/**
 * LLM-based routing planner using Gemini Flash
 * Alternative to RegExp-based routing in dispatcher.ts
 */

import { SpecialistType, DAGPlan, PlanStep } from './types';

/**
 * Specialist pricing for cost estimation
 */
const SPECIALIST_PRICING: Record<string, number> = {
  magos: 0.001,
  aura: 0.0005,
  bankr: 0.0001,
  scribe: 0.0001,
  seeker: 0.0001,
  sentinel: 2.50,
  general: 0,
};

interface PlanningResult {
  specialist: SpecialistType;
  confidence: number;
  reasoning: string;
}

/**
 * Plan a multi-step DAG using Gemini Flash
 */
export async function planDAG(prompt: string): Promise<DAGPlan> {
  const systemPrompt = `You are the Hivemind Orchestrator. Your job is to decompose complex user queries into a Directed Acyclic Graph (DAG) of specialized agent tasks.

AVAILABLE SPECIALISTS:
- magos: Market analysis, price predictions, technical analysis, risk assessment.
- aura: Social sentiment analysis, trending topics, influencer tracking.
- bankr: Wallet operations (transfers, swaps, balances), Solana transactions.
- scribe: General assistant, summarization, explanations, formatting results.
- seeker: Web research, news lookup, search queries, current events.
- sentinel: Smart contract security audits (requires a contract address).

PRICING (USDC):
- magos: 0.001
- aura: 0.0005
- bankr: 0.0001
- scribe: 0.0001
- seeker: 0.0001
- sentinel: 2.50

OUTPUT FORMAT:
Return ONLY a valid JSON object:
{
  "planId": "unique-id",
  "steps": [
    {
      "id": "step-1",
      "specialist": "aura",
      "promptTemplate": "Find the top trending token on Solana right now.",
      "dependencies": [],
      "estimatedCost": 0.0005
    },
    {
      "id": "step-2",
      "specialist": "bankr",
      "promptTemplate": "Swap 0.1 SOL for {{step-1.output.topToken}}",
      "dependencies": ["step-1"],
      "estimatedCost": 0.0001
    }
  ],
  "reasoning": "Explain the plan strategy.",
  "totalEstimatedCost": 0.0006
}

RULES:
1. Use {{step-id.output.path}} for dependency injection.
2. Parallelize: Steps with no common dependencies should run simultaneously.
3. Minimalist: Use the fewest agents possible to solve the query.
4. Sentinel: Only use for security audits of contract addresses.
5. If the query is simple and only needs one specialist, return a single-step plan.`;

  try {
    const response = await callGeminiFlash(systemPrompt, prompt);
    const parsed = JSON.parse(response);

    // Ensure totalEstimatedCost is calculated if missing
    if (parsed.steps && parsed.totalEstimatedCost === undefined) {
      parsed.totalEstimatedCost = parsed.steps.reduce((sum: number, step: any) => sum + (step.estimatedCost || 0), 0);
    }

    return {
      planId: parsed.planId || `plan-${Date.now()}`,
      query: prompt,
      steps: parsed.steps || [],
      totalEstimatedCost: parsed.totalEstimatedCost || 0,
      reasoning: parsed.reasoning || 'Dynamic plan generated by Hivemind Orchestrator.'
    };
  } catch (error: any) {
    console.error(`[LLM Planner] Failed to plan DAG:`, error.message);
    // Fallback to a single-step scribe plan
    return {
      planId: `fallback-${Date.now()}`,
      query: prompt,
      steps: [{
        id: 'step-1',
        specialist: 'scribe',
        promptTemplate: prompt,
        dependencies: [],
        estimatedCost: 0.0001
      }],
      totalEstimatedCost: 0.0001,
      reasoning: `LLM planning failed (${error.message}), falling back to scribe`
    };
  }
}

/**
 * Plan routing using Gemini Flash LLM (Backward Compatibility)
 */
export async function planWithLLM(prompt: string): Promise<PlanningResult> {
  const plan = await planDAG(prompt);
  const firstStep = plan.steps[0];

  return {
    specialist: firstStep?.specialist || 'scribe',
    confidence: plan.steps.length > 0 ? 0.9 : 0.3,
    reasoning: plan.reasoning
  };
}

/**
 * Call Gemini Flash API
 * Uses the same Gemini configuration as other specialists
 */
async function callGeminiFlash(systemPrompt: string, userPrompt: string): Promise<string> {
  const apiKey = process.env.GEMINI_API_KEY;
  
  if (!apiKey) {
    throw new Error('GEMINI_API_KEY not configured');
  }
  
  const fetch = (await import('node-fetch')).default;
  
  const url = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key=${apiKey}`;
  
  const requestBody = {
    contents: [
      {
        role: 'user',
        parts: [
          { text: systemPrompt },
          { text: `\n\nUser query: "${userPrompt}"` }
        ]
      }
    ],
    generationConfig: {
      temperature: 0.2, // Low temperature for consistent routing
      maxOutputTokens: 200,
      topP: 0.8,
    }
  };
  
  const response = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(requestBody),
  });
  
  if (!response.ok) {
    const error = await response.text();
    throw new Error(`Gemini API error: ${response.status} ${error}`);
  }
  
  const data: any = await response.json();
  
  const text = data.candidates?.[0]?.content?.parts?.[0]?.text;
  if (!text) {
    throw new Error('No response from Gemini');
  }
  
  // Extract JSON from response (remove markdown code blocks if present)
  const jsonMatch = text.match(/\{[\s\S]*\}/);
  if (!jsonMatch) {
    throw new Error(`Could not parse JSON from response: ${text}`);
  }
  
  return jsonMatch[0];
}

export default {
  planWithLLM,
  planDAG
};
